services:
  data_processing_save_ids:
    build:
      context: .
      dockerfile: ./docker/1_Data_Processing_save_ids/Dockerfile
    volumes:
      - ./data:/data  # Mount the ./data folder from the host to /data in the container
    tty: true
    container_name: data_processing_save_ids
    environment:
      - PYTHONUNBUFFERED=1

  data_processing_save_entities:
    build:
      context: .
      dockerfile: ./docker/2_Data_Processing_save_entities/Dockerfile
    volumes:
      - ./data:/data  # Mount the ./data folder from the host to /data in the container
    tty: true
    container_name: data_processing_save_entities
    environment:
      - PYTHONUNBUFFERED=1

  add_wikidata_to_astra:
    build:
      context: .
      dockerfile: ./docker/3_Add_Wikidata_to_AstraDB/Dockerfile
    volumes:
      - ./data:/data
    tty: true
    container_name: add_wikidata_to_astra
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      PYTHONUNBUFFERED: 1
      JINA: "true"
      SAMPLE: "false"
      API_KEY: "datastax_wikidata_nvidia.json"
      BATCH_SIZE: 8
      OFFSET: 0
      COLLECTION_NAME: "wikidata_jina"

  run_retrieval:
    build:
      context: .
      dockerfile: ./docker/4_Run_Retrieval/Dockerfile
    volumes:
      - ./data:/data
    tty: true
    container_name: run_retrieval
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    environment:
      PYTHONUNBUFFERED: 1
      NVIDIA: "true"
      API_KEY: "datastax_wikidata_nvidia.json"
      COLLECTION_NAME: "wikidata"
      BATCH_SIZE: 6
      EVALUATION_PATH: "Wikidata-Disamb/processed_dataframe_filtered.pkl"
      COMPARATIVE: "true"
      COMPARATIVE_COLS: "Correct QID,Wrong QID"
      QUERY_COL: "Sentence"
      LANGUAGE: "en"