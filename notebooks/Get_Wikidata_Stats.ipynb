{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to read and process the Wikdata dump file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from wikidataDumpReader import WikidataDumpReader\n",
    "from multiprocessing import Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH = '../data/Wikidata/latest-all.json.bz2'\n",
    "QUEUE_SIZE = 15000\n",
    "NUM_PROCESSES = 4\n",
    "SKIPLINES = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocess_manager = Manager()\n",
    "\n",
    "wikipedialang_counts = multiprocess_manager.dict() # Per language, count the the items that are connected to the Wikipedia page of the language\n",
    "\n",
    "wikidatalang_counts = multiprocess_manager.dict() # Per language, count the the items that have a label and description supported in the language\n",
    "wikidatalang_counts_wikionly = multiprocess_manager.dict() # Same as wikidatalang_counts but for items that are connected to a Wikipedia page\n",
    "\n",
    "wikidata_wikipedia_lang_counts = multiprocess_manager.dict() # The intersection of wikipedialang_counts and wikidatalang_counts.\n",
    "\n",
    "claim_counts = multiprocess_manager.dict() # Per claim, count how many times it's been included in an item\n",
    "claim_counts_wikionly = multiprocess_manager.dict() # Same as claim_counts but for items that are connected to a Wikipedia page\n",
    "\n",
    "instanceof_counts = multiprocess_manager.dict() # Count the distinct values of instance of claim\n",
    "instanceof_counts_wikionly = multiprocess_manager.dict() # Same as instanceof_counts but for items that are connected to a Wikipedia page\n",
    "\n",
    "item_type_count = multiprocess_manager.dict() # Number of QIDs vs PIDs vs LIDs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_lang(entity):\n",
    "    \"\"\"\n",
    "    Return the languages of all Wikipedia pages connected to the Wikidata entity.\n",
    "    \"\"\"\n",
    "    langs = set()\n",
    "    if ('sitelinks' in entity):\n",
    "        for s in entity['sitelinks']:\n",
    "            if s.endswith('wiki'):\n",
    "                langs.add(s.split('wiki')[0])\n",
    "    return langs\n",
    "\n",
    "def get_wikidata_lang(entity):\n",
    "    \"\"\"\n",
    "    Return the languages supported in this Wikidata entity (label and description)\n",
    "    \"\"\"\n",
    "    label_langs = set(entity.get('labels', {}).keys())\n",
    "    desc_langs = set(entity.get('descriptions', {}).keys())\n",
    "    return label_langs.intersection(desc_langs)\n",
    "\n",
    "def get_claims_pids(entity):\n",
    "    \"\"\"\n",
    "    Return the list of properties connected to the Wikidata entity.\n",
    "    \"\"\"\n",
    "    pids_count = {}\n",
    "    for pid,claim in entity.get('claims', {}).items():\n",
    "        pids_count[pid] = pids_count.get(pid, 0) +1\n",
    "\n",
    "        for c in claim:\n",
    "            if 'qualifiers' in c:\n",
    "                for pid,_ in c['qualifiers'].items():\n",
    "                    pids_count[pid] = pids_count.get(pid, 0) +1\n",
    "    return pids_count\n",
    "\n",
    "def get_instanceof(entity):\n",
    "    \"\"\"\n",
    "    Return the instance of QID values\n",
    "    \"\"\"\n",
    "    instanceof = set()\n",
    "    if 'P31' in entity.get('claims', {}):\n",
    "        for c in entity['claims']['P31']:\n",
    "            if ('mainsnak' in c) and ('datavalue' in c['mainsnak']):\n",
    "                if (c['mainsnak'].get('datatype', '') == 'wikibase-item'):\n",
    "                    qid = c['mainsnak']['datavalue']['value']['id']\n",
    "                    instanceof.add(qid)\n",
    "    return instanceof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(item, item_type_count, wikipedialang_counts, wikidatalang_counts, wikidatalang_counts_wikionly, claim_counts, claim_counts_wikionly, instanceof_counts, instanceof_counts_wikionly, wikidata_wikipedia_lang_counts):\n",
    "    if (item is not None):\n",
    "        id_type = item['id'][0]\n",
    "        wikipedialangs = get_wikipedia_lang(item)\n",
    "        wikidatalangs = get_wikidata_lang(item)\n",
    "        claimspids = get_claims_pids(item)\n",
    "        instanceof = get_instanceof(item)\n",
    "\n",
    "        item_type_count[id_type] = item_type_count.get(id_type, 0) +1\n",
    "\n",
    "        if id_type == 'Q':\n",
    "            for lang in wikipedialangs:\n",
    "                wikipedialang_counts[lang] = wikipedialang_counts.get(lang, 0) +1\n",
    "\n",
    "            for lang in wikidatalangs:\n",
    "                wikidatalang_counts[lang] = wikidatalang_counts.get(lang, 0) +1\n",
    "\n",
    "            for pid, count in claimspids.items():\n",
    "                claim_counts[pid] = claim_counts.get(pid, 0) + count\n",
    "\n",
    "            for qid in instanceof:\n",
    "                instanceof_counts[qid] = instanceof_counts.get(qid, 0) +1\n",
    "\n",
    "            if len(wikipedialangs) > 0:\n",
    "                wikipedialang_counts['total']  = wikipedialang_counts.get('total', 0) +1\n",
    "\n",
    "                for lang in wikidatalangs:\n",
    "                    wikidatalang_counts_wikionly[lang] = wikidatalang_counts_wikionly.get(lang, 0) +1\n",
    "\n",
    "                for pid, count in claimspids.items():\n",
    "                    claim_counts_wikionly[pid] = claim_counts_wikionly.get(pid, 0) + count\n",
    "\n",
    "                for qid in instanceof:\n",
    "                    instanceof_counts_wikionly[qid] = instanceof_counts_wikionly.get(qid, 0) +1\n",
    "\n",
    "            for lang in wikidatalangs.intersection(wikipedialangs):\n",
    "                wikidata_wikipedia_lang_counts[lang] = wikidata_wikipedia_lang_counts.get(lang, 0) +1\n",
    "\n",
    "\n",
    "wikidata = WikidataDumpReader(FILEPATH, num_processes=NUM_PROCESSES, queue_size=QUEUE_SIZE, skiplines=SKIPLINES)\n",
    "wikidata.run(lambda item: calculate_stats(item, item_type_count, wikipedialang_counts, wikidatalang_counts, wikidatalang_counts_wikionly, claim_counts, claim_counts_wikionly, instanceof_counts, instanceof_counts_wikionly, wikidata_wikipedia_lang_counts), max_iterations=1000, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
