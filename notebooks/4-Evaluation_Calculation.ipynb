{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "os.environ[\"LANGUAGE\"] = 'ar'\n",
    "\n",
    "from sqlalchemy.sql.expression import func\n",
    "from wikidataDB import WikidataEntity, WikidataID, Session\n",
    "from wikidataRetriever import WikidataKeywordSearch, AstraDBConnect\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def is_in_wikipedia(qid):\n",
    "    item = WikidataID.get_id(qid)\n",
    "    if item is None:\n",
    "        return False\n",
    "    return item.in_wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Evaluation Data/retrieval_results_REDFM-wikidata_test_v1-DB(en,ar)-Query(EN)_DB-AR-EN_Query-EN.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Evaluation Data/retrieval_results_REDFM-wikidata_test_v1-DB(en,ar)-Query(EN)_DB-AR-EN_Query-EN.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# directory = '../data/Evaluation Data/Language Results/REDFM-noentity'\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# for file in os.listdir(directory):\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m prep \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(prep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieval QIDs\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# For Mintaka, LC_QuAD, and RuBQ\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# prep = prep[prep.apply(lambda x: all(x['Question in Wikipedia'] + x['Answer in Wikipedia']), axis=1)]\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# prep['Correct QIDs'] = prep.apply(lambda x: x['Question QIDs'] + x['Answer QIDs'], axis=1)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# For REDFM\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Evaluation Data/retrieval_results_REDFM-wikidata_test_v1-DB(en,ar)-Query(EN)_DB-AR-EN_Query-EN.pkl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def calculate_mrr_score(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    # Return the MRR\n",
    "    return ranks.apply(lambda x: 1/x[0] if len(x)>0 else 0).mean()\n",
    "\n",
    "def calculate_ndcg_score(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    # Calculate the DCG, the Ideal DCG and finally return the NDCG\n",
    "    dcg = ranks.apply(lambda x: sum([1/np.log2(y+1) for y in x]) if len(x)>0 else 0)\n",
    "    idcg = df.apply(lambda x: sum([1/np.log2(y+1) for y in range(1, min(len(x[true_cols]), len(x[pred_col])) + 1)]), axis=1)\n",
    "    return (dcg/idcg).mean()\n",
    "\n",
    "collection = \"wikidata_test_v1\"\n",
    "evaluation_dataset = \"REDFM\"\n",
    "filename = f\"retrieval_results_{evaluation_dataset}-{collection}-arwithentity_DB-AR_EN_DE_Query-AR\"\n",
    "filename = f\"../data/Evaluation Data/retrieval_results_REDFM-wikidata_test_v1-DB(en,ar)-Query(EN)_DB-AR-EN_Query-EN.pkl\"\n",
    "\n",
    "# directory = '../data/Evaluation Data/Language Results/REDFM-noentity'\n",
    "# for file in os.listdir(directory):\n",
    "prep = pickle.load(open(filename, \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "\n",
    "# For Mintaka, LC_QuAD, and RuBQ\n",
    "# prep = prep[prep.apply(lambda x: all(x['Question in Wikipedia'] + x['Answer in Wikipedia']), axis=1)]\n",
    "# prep['Correct QIDs'] = prep.apply(lambda x: x['Question QIDs'] + x['Answer QIDs'], axis=1)\n",
    "\n",
    "# For REDFM\n",
    "prep = prep[prep['Correct in Wikipedia']]\n",
    "prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "print(file)\n",
    "print(\"MRR:\")\n",
    "print(calculate_mrr_score(prep, 'Retrieval QIDs', 'Correct QIDs'))\n",
    "print(\"NDCG:\")\n",
    "print(calculate_ndcg_score(prep, 'Retrieval QIDs', 'Correct QIDs'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9290f2a271045ca88e1bd94e9f95997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69ecec8bd2a41b9a10e06f25b83d2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b81d7daad84e7fa0919cc22e59ff55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from wikidataDB import WikidataEntity\n",
    "from wikidataEmbed import WikidataTextifier, JinaAIReranker\n",
    "\n",
    "collection = \"wikidata_test_v1\"\n",
    "evaluation_dataset = \"Mintaka\"\n",
    "filename = f\"retrieval_results_{evaluation_dataset}-{collection}-de_DB-EN_Query-DE\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/{filename}.pkl\", \"rb\"))\n",
    "\n",
    "textifier = WikidataTextifier(with_claim_aliases=False, with_property_aliases=False, language='en')\n",
    "reranker = JinaAIReranker()\n",
    "\n",
    "def rerank_qids(query, qids, reranker, textifier):\n",
    "    entities = [WikidataEntity.get_entity(qid) for qid in qids]\n",
    "    texts = [textifier.entity_to_text(entity) for entity in entities]\n",
    "    scores = reranker.rank(query, texts)\n",
    "\n",
    "    score_zip = zip(scores, prep.iloc[0]['Retrieval QIDs'])\n",
    "    score_zip = sorted(score_zip, key=lambda x: -x[0])\n",
    "    return [x[1] for x in score_zip]\n",
    "\n",
    "scores = rerank_qids(prep.iloc[0]['Question'], prep.iloc[0]['Retrieval QIDs'], reranker, textifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question QIDs</th>\n",
       "      <th>Answer QIDs</th>\n",
       "      <th>Question in Wikipedia</th>\n",
       "      <th>Answer in Wikipedia</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Answer Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>Retrieval QIDs</th>\n",
       "      <th>Retrieval Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q1497, Q846570]</td>\n",
       "      <td>[Q7245]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>What man was a famous American author and also...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>[Q1131648, Q1249322, Q863037, Q23434, Q7846597...</td>\n",
       "      <td>[0.7380401, 0.7190001, 0.71705467, 0.7165503, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Q133313, Q19020]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>How many Academy Awards has Jake Gyllenhaal be...</td>\n",
       "      <td>1</td>\n",
       "      <td>numerical</td>\n",
       "      <td>en</td>\n",
       "      <td>[Q181883, Q2665878, Q518675, Q181883, Q5887360...</td>\n",
       "      <td>[0.70622474, 0.7047322, 0.70396847, 0.70157534...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[Q2121062, Q33240]</td>\n",
       "      <td>[Q33240]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>Who is older, The Weeknd or Drake?</td>\n",
       "      <td>Drake</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>[Q33240, Q33240, Q2121062, Q2121062, Q6078, Q2...</td>\n",
       "      <td>[0.7515571, 0.747073, 0.72907823, 0.7220057, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[Q22686]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>How many children did Donald Trump have?</td>\n",
       "      <td>5</td>\n",
       "      <td>numerical</td>\n",
       "      <td>en</td>\n",
       "      <td>[Q22686, Q22686, Q22686, Q22686, Q12071552, Q2...</td>\n",
       "      <td>[0.7423017, 0.73196423, 0.7283923, 0.72393155,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[Q474573, Q1060306]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Is the main hero in Final Fantasy IX named Kuja?</td>\n",
       "      <td>No</td>\n",
       "      <td>boolean</td>\n",
       "      <td>en</td>\n",
       "      <td>[Q1060306, Q474573, Q1334722, Q223381, Q179859...</td>\n",
       "      <td>[0.8902929, 0.77739924, 0.7597104, 0.75929916,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179955</th>\n",
       "      <td>[Q736865]</td>\n",
       "      <td>[Q588289]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>What kind of game is Zeus Master of Olympus?</td>\n",
       "      <td>city building</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179964</th>\n",
       "      <td>[Q2299192]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>How many games by Impressions Games were relea...</td>\n",
       "      <td>2</td>\n",
       "      <td>numerical</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179973</th>\n",
       "      <td>[Q2299192, Q588289]</td>\n",
       "      <td>[Q510054]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>What is the newest city building game develope...</td>\n",
       "      <td>Emperor: Rise of the Middle Kingdom</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179982</th>\n",
       "      <td>[Q42310881]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>What is the most expensive fish in Animal Cros...</td>\n",
       "      <td>King Koi, King Red Snapper</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179991</th>\n",
       "      <td>[Q8409]</td>\n",
       "      <td>[Q217414]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>Where did the first wife of Alexander the Grea...</td>\n",
       "      <td>Amphipolis</td>\n",
       "      <td>entity</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Question QIDs Answer QIDs Question in Wikipedia  \\\n",
       "0          [Q1497, Q846570]     [Q7245]          [True, True]   \n",
       "9         [Q133313, Q19020]          []          [True, True]   \n",
       "18       [Q2121062, Q33240]    [Q33240]          [True, True]   \n",
       "27                 [Q22686]          []                [True]   \n",
       "36      [Q474573, Q1060306]          []          [True, True]   \n",
       "...                     ...         ...                   ...   \n",
       "179955            [Q736865]   [Q588289]                [True]   \n",
       "179964           [Q2299192]          []                [True]   \n",
       "179973  [Q2299192, Q588289]   [Q510054]          [True, True]   \n",
       "179982          [Q42310881]          []                [True]   \n",
       "179991              [Q8409]   [Q217414]                [True]   \n",
       "\n",
       "       Answer in Wikipedia                                           Question  \\\n",
       "0                   [True]  What man was a famous American author and also...   \n",
       "9                       []  How many Academy Awards has Jake Gyllenhaal be...   \n",
       "18                  [True]                 Who is older, The Weeknd or Drake?   \n",
       "27                      []           How many children did Donald Trump have?   \n",
       "36                      []   Is the main hero in Final Fantasy IX named Kuja?   \n",
       "...                    ...                                                ...   \n",
       "179955              [True]       What kind of game is Zeus Master of Olympus?   \n",
       "179964                  []  How many games by Impressions Games were relea...   \n",
       "179973              [True]  What is the newest city building game develope...   \n",
       "179982                  []  What is the most expensive fish in Animal Cros...   \n",
       "179991              [True]  Where did the first wife of Alexander the Grea...   \n",
       "\n",
       "                                     Answer Answer Type Language  \\\n",
       "0                                Mark Twain      entity       en   \n",
       "9                                         1   numerical       en   \n",
       "18                                    Drake      entity       en   \n",
       "27                                        5   numerical       en   \n",
       "36                                       No     boolean       en   \n",
       "...                                     ...         ...      ...   \n",
       "179955                        city building      entity       en   \n",
       "179964                                    2   numerical       en   \n",
       "179973  Emperor: Rise of the Middle Kingdom      entity       en   \n",
       "179982           King Koi, King Red Snapper      entity       en   \n",
       "179991                           Amphipolis      entity       en   \n",
       "\n",
       "                                           Retrieval QIDs  \\\n",
       "0       [Q1131648, Q1249322, Q863037, Q23434, Q7846597...   \n",
       "9       [Q181883, Q2665878, Q518675, Q181883, Q5887360...   \n",
       "18      [Q33240, Q33240, Q2121062, Q2121062, Q6078, Q2...   \n",
       "27      [Q22686, Q22686, Q22686, Q22686, Q12071552, Q2...   \n",
       "36      [Q1060306, Q474573, Q1334722, Q223381, Q179859...   \n",
       "...                                                   ...   \n",
       "179955                                               None   \n",
       "179964                                               None   \n",
       "179973                                               None   \n",
       "179982                                               None   \n",
       "179991                                               None   \n",
       "\n",
       "                                          Retrieval Score  \n",
       "0       [0.7380401, 0.7190001, 0.71705467, 0.7165503, ...  \n",
       "9       [0.70622474, 0.7047322, 0.70396847, 0.70157534...  \n",
       "18      [0.7515571, 0.747073, 0.72907823, 0.7220057, 0...  \n",
       "27      [0.7423017, 0.73196423, 0.7283923, 0.72393155,...  \n",
       "36      [0.8902929, 0.77739924, 0.7597104, 0.75929916,...  \n",
       "...                                                   ...  \n",
       "179955                                               None  \n",
       "179964                                               None  \n",
       "179973                                               None  \n",
       "179982                                               None  \n",
       "179991                                               None  \n",
       "\n",
       "[20000 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = f\"retrieval_results_{evaluation_dataset}-{collection}-en_DB-EN_Query-EN\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/{filename}.pkl\", \"rb\"))\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy_score(df):\n",
    "    highest_score_idx = df['Retrieval Score'].apply(np.argmax)\n",
    "    top_qid = df.apply(lambda x: x['Retrieval QIDs'][highest_score_idx[x.name]], axis=1)\n",
    "    return (top_qid == df['Correct QID']).mean()\n",
    "\n",
    "def calculate_log_odds_ratio_score(df):\n",
    "    def log_odds_ratio(row):\n",
    "        correct_qid = row['Correct QID']\n",
    "        wrong_qid = row['Wrong QID']\n",
    "\n",
    "        # Find the maximum scores for the correct and wrong QIDs\n",
    "        correct_scores = [score for qid, score in zip(row['Retrieval QIDs'], row['Retrieval Score']) if qid == correct_qid]\n",
    "        wrong_scores = [score for qid, score in zip(row['Retrieval QIDs'], row['Retrieval Score']) if qid == wrong_qid]\n",
    "\n",
    "        max_correct_score = max(correct_scores, default=0)\n",
    "        max_wrong_score = max(wrong_scores, default=0)\n",
    "\n",
    "        correct_log_odds = np.log(max_correct_score / (1 - max_correct_score))\n",
    "        wrong_log_odds = np.log(max_wrong_score / (1 - max_wrong_score))\n",
    "        return correct_log_odds - wrong_log_odds\n",
    "\n",
    "    # Apply the log odds ratio calculation to each row\n",
    "    return df.apply(log_odds_ratio, axis=1).mean()\n",
    "\n",
    "collection = \"wikidata_test_v2\"\n",
    "evaluation_dataset = \"Wikidata-Disamb\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "\n",
    "calculate_accuracy_score(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_accuracy_over_K(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    ranks = ranks.apply(lambda x: min(x) if len(x) > 0 else None)\n",
    "\n",
    "    accuracy = [(ranks <= i).mean() for i in range(int(ranks.max()))]\n",
    "    return accuracy\n",
    "\n",
    "collection = \"wikidata_test_v1\"\n",
    "evaluation_dataset = \"REDFM\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "prep = prep[prep['Correct in Wikipedia']]\n",
    "prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "accuracy_v1 = calculate_accuracy_over_K(prep, 'Retrieval QIDs', 'Correct QIDs')\n",
    "\n",
    "collection = \"wikidata_test_v2\"\n",
    "evaluation_dataset = \"REDFM\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "prep = prep[prep['Correct in Wikipedia']]\n",
    "prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "accuracy_v2 = calculate_accuracy_over_K(prep, 'Retrieval QIDs', 'Correct QIDs')\n",
    "\n",
    "# Create a simple bar chart\n",
    "plt.plot(list(range(len(accuracy_v1))), np.array(accuracy_v1)*100, label='Jina')\n",
    "plt.plot(list(range(len(accuracy_v2))), np.array(accuracy_v2)*100, label='Nvidia')\n",
    "plt.title('Accuracy of 1 correct item in REDFM')\n",
    "plt.xlabel('# Entities Retrieved')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import func\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modified query with random ordering\n",
    "sample_count = sample_ids['from Evaluation'].sum()*2 - (~sample_ids['from Evaluation']).sum()\n",
    "with tqdm(total=sample_count) as progressbar:\n",
    "    with Session() as session:\n",
    "        entities = (\n",
    "            session.query(WikidataID)\n",
    "            .filter(WikidataID.in_wikipedia == True)\n",
    "            .order_by(func.random())  # Adds random ordering\n",
    "            .yield_per(1000)\n",
    "        )\n",
    "\n",
    "        # Example of iterating through the entities\n",
    "        for entity in tqdm(entities):\n",
    "            if entity.id not in sample_ids['QID'].values:\n",
    "                sample_ids = pd.concat([sample_ids, pd.DataFrame([{\n",
    "                        'QID': entity.id,\n",
    "                        'from Evaluation': False,\n",
    "                        'In Wikipedia': True,\n",
    "                        'Sample 2': True\n",
    "                    }])], ignore_index=True)\n",
    "                progressbar.update(1)\n",
    "            if progressbar.n >= sample_count:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# prep = pickle.load(open(\"/home/philippe.saade/GitHub/WikidataTextEmbedding/data/Evaluation Data/KGConv/processed_dataframe.pkl\", \"rb\"))\n",
    "\n",
    "sample_ids = pickle.load(open(\"../data/Evaluation Data/Sample IDs (EN).pkl\", \"rb\"))\n",
    "sample_ids = sample_ids[sample_ids['In Wikipedia']]\n",
    "\n",
    "sample_qids_set = set(sample_ids['QID'].values)\n",
    "\n",
    "# Use vectorized operations for 'not_in_sample'\n",
    "# prep['Question in Wikipedia'] = prep['Question QID'].isin(sample_qids_set)\n",
    "# prep['Answer in Wikipedia'] = prep['Answer QID'].isin(sample_qids_set)\n",
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids[sample_ids['Sample 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(prep.iterrows()):\n",
    "    for i in range(len(row['Answer QIDs'])):\n",
    "        if row['Answer in Wikipedia'][i] and row['Answer QIDs'][i] not in sample_qids_set:\n",
    "            sample_ids = pd.concat([sample_ids, pd.DataFrame([{\n",
    "                'QID': row['Answer QIDs'][i],\n",
    "                'from Evaluation': True,\n",
    "                'In Wikipedia': True,\n",
    "                'from Evaluation 2': True\n",
    "            }])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spans(sentence, spans, replace_with='Entity'):\n",
    "    # Sort spans in ascending order to remove from left to right\n",
    "    spans = sorted(spans, key=lambda x: x[0])\n",
    "    offset = 0  # To track the shift in index after replacing each span\n",
    "\n",
    "    for start, end in spans:\n",
    "        sentence = sentence[:start - offset] + replace_with + sentence[end - offset:]\n",
    "        offset += (end - start) - len(replace_with)  # Update offset to account for the replaced span length\n",
    "\n",
    "    return sentence\n",
    "\n",
    "data['Sentence no entity'] = data.apply(lambda x: remove_spans(x['Sentence'], x['Entity Span']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
