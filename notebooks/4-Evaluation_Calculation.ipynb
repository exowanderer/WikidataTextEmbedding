{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import os\n",
    "os.environ[\"LANGUAGE\"] = 'ar'\n",
    "\n",
    "from sqlalchemy.sql.expression import func\n",
    "from wikidataDB import WikidataEntity, WikidataID, Session\n",
    "from wikidataRetriever import WikidataKeywordSearch, AstraDBConnect\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def is_in_wikipedia(qid):\n",
    "    item = WikidataID.get_id(qid)\n",
    "    if item is None:\n",
    "        return False\n",
    "    return item.in_wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question QIDs</th>\n",
       "      <th>Answer QIDs</th>\n",
       "      <th>Question in Wikipedia</th>\n",
       "      <th>Answer in Wikipedia</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Answer Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>Retrieval QIDs</th>\n",
       "      <th>Retrieval Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q1497, Q846570]</td>\n",
       "      <td>[Q7245]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>مَن الرجل الذي كان مؤلفًا أمريكيًا مشهورًا وعم...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Q133313, Q19020]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>كم عدد جوائز الأوسكار التي ترشح لها الممثل جيك...</td>\n",
       "      <td>1</td>\n",
       "      <td>numerical</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[Q2121062, Q33240]</td>\n",
       "      <td>[Q33240]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>أيهما أكبر سنًا، The Weeknd أم Drake؟</td>\n",
       "      <td>Drake</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[Q22686]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>كم عدد أطفال دونالد ترامب؟</td>\n",
       "      <td>5</td>\n",
       "      <td>numerical</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[Q152283, Q361]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[]</td>\n",
       "      <td>كم عدد الدول التي كانت في تحالف \"قوى المحور\" ف...</td>\n",
       "      <td>4</td>\n",
       "      <td>numerical</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179848</th>\n",
       "      <td>[Q29468, Q100]</td>\n",
       "      <td>[Q3281706]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>مَن هو آخر عمدة جمهوري في بوسطن؟</td>\n",
       "      <td>Malcolm Nichols</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179875</th>\n",
       "      <td>[Q62]</td>\n",
       "      <td>[Q795590]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>مَن ثالث عمدة في سان فرانسيسكو؟</td>\n",
       "      <td>Stephen Randall Harris</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179893</th>\n",
       "      <td>[Q269412]</td>\n",
       "      <td>[Q166714]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>من كان أول رئيس وزراء في عهد جورج الخامس؟</td>\n",
       "      <td>H. H. Asquith</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179902</th>\n",
       "      <td>[Q9682]</td>\n",
       "      <td>[Q8016]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>مَن هو أول رئيس وزراء أثناء حكم إليزبيث الثانية؟</td>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179911</th>\n",
       "      <td>[Q9682, Q9630]</td>\n",
       "      <td>[Q128956]</td>\n",
       "      <td>[True, True]</td>\n",
       "      <td>[True]</td>\n",
       "      <td>مَن هو أول رئيس وزراء من حزب العمال أثناء حكم ...</td>\n",
       "      <td>Harold Wilson</td>\n",
       "      <td>entity</td>\n",
       "      <td>ar</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11720 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Question QIDs Answer QIDs Question in Wikipedia  \\\n",
       "1         [Q1497, Q846570]     [Q7245]          [True, True]   \n",
       "10       [Q133313, Q19020]          []          [True, True]   \n",
       "19      [Q2121062, Q33240]    [Q33240]          [True, True]   \n",
       "28                [Q22686]          []                [True]   \n",
       "64         [Q152283, Q361]          []          [True, True]   \n",
       "...                    ...         ...                   ...   \n",
       "179848      [Q29468, Q100]  [Q3281706]          [True, True]   \n",
       "179875               [Q62]   [Q795590]                [True]   \n",
       "179893           [Q269412]   [Q166714]                [True]   \n",
       "179902             [Q9682]     [Q8016]                [True]   \n",
       "179911      [Q9682, Q9630]   [Q128956]          [True, True]   \n",
       "\n",
       "       Answer in Wikipedia                                           Question  \\\n",
       "1                   [True]  مَن الرجل الذي كان مؤلفًا أمريكيًا مشهورًا وعم...   \n",
       "10                      []  كم عدد جوائز الأوسكار التي ترشح لها الممثل جيك...   \n",
       "19                  [True]              أيهما أكبر سنًا، The Weeknd أم Drake؟   \n",
       "28                      []                         كم عدد أطفال دونالد ترامب؟   \n",
       "64                      []  كم عدد الدول التي كانت في تحالف \"قوى المحور\" ف...   \n",
       "...                    ...                                                ...   \n",
       "179848              [True]                   مَن هو آخر عمدة جمهوري في بوسطن؟   \n",
       "179875              [True]                    مَن ثالث عمدة في سان فرانسيسكو؟   \n",
       "179893              [True]          من كان أول رئيس وزراء في عهد جورج الخامس؟   \n",
       "179902              [True]   مَن هو أول رئيس وزراء أثناء حكم إليزبيث الثانية؟   \n",
       "179911              [True]  مَن هو أول رئيس وزراء من حزب العمال أثناء حكم ...   \n",
       "\n",
       "                        Answer Answer Type Language Retrieval QIDs  \\\n",
       "1                   Mark Twain      entity       ar             []   \n",
       "10                           1   numerical       ar             []   \n",
       "19                       Drake      entity       ar             []   \n",
       "28                           5   numerical       ar             []   \n",
       "64                           4   numerical       ar             []   \n",
       "...                        ...         ...      ...            ...   \n",
       "179848         Malcolm Nichols      entity       ar             []   \n",
       "179875  Stephen Randall Harris      entity       ar             []   \n",
       "179893           H. H. Asquith      entity       ar             []   \n",
       "179902       Winston Churchill      entity       ar             []   \n",
       "179911           Harold Wilson      entity       ar             []   \n",
       "\n",
       "       Retrieval Score  \n",
       "1                   []  \n",
       "10                  []  \n",
       "19                  []  \n",
       "28                  []  \n",
       "64                  []  \n",
       "...                ...  \n",
       "179848              []  \n",
       "179875              []  \n",
       "179893              []  \n",
       "179902              []  \n",
       "179911              []  \n",
       "\n",
       "[11720 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"retrieval_results_Mintaka-wikidata_langtest-DB()-Query(ar).pkl\"\n",
    "filename = f\"{directory}/{file}\"\n",
    "prep = pickle.load(open(filename, \"rb\"))\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval_results_LC_QuAD-wikidata_langtest-DB(en)-Query(en).pkl\n",
      "MRR:\n",
      "0.8577808582963308\n",
      "NDCG:\n",
      "0.7616046523775921\n",
      "\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB(en)-Query(de).pkl\n",
      "MRR:\n",
      "0.6222371309371194\n",
      "NDCG:\n",
      "0.4764445167151068\n",
      "\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB()-Query(en).pkl\n",
      "Evaluation not complete\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB(ar)-Query(ar).pkl\n",
      "MRR:\n",
      "0.7974359339458562\n",
      "NDCG:\n",
      "0.7039236233522335\n",
      "\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB(en,de)-Query(en).pkl\n",
      "MRR:\n",
      "0.6522342043502821\n",
      "NDCG:\n",
      "0.5010180817898566\n",
      "\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB()-Query(ar).pkl\n",
      "Evaluation not complete\n",
      "retrieval_results_LC_QuAD-wikidata_langtest-DB(de)-Query(de).pkl\n",
      "MRR:\n",
      "0.846602963540312\n",
      "NDCG:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(calculate_mrr_score(prep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieval QIDs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect QIDs\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDCG:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(calculate_ndcg_score(prep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieval QIDs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect QIDs\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m, in \u001b[0;36mcalculate_ndcg_score\u001b[0;34m(df, pred_col, true_cols)\u001b[0m\n\u001b[1;32m     14\u001b[0m prep[pred_col] \u001b[38;5;241m=\u001b[39m prep[pred_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(x)))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Get the rank of each retrieved QID\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m ranks \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x[pred_col])) \u001b[38;5;28;01mif\u001b[39;00m (x[pred_col][i] \u001b[38;5;129;01min\u001b[39;00m x[true_cols])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate the DCG, the Ideal DCG and finally return the NDCG\u001b[39;00m\n\u001b[1;32m     18\u001b[0m dcg \u001b[38;5;241m=\u001b[39m ranks\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(y\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[20], line 16\u001b[0m, in \u001b[0;36mcalculate_ndcg_score.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m prep[pred_col] \u001b[38;5;241m=\u001b[39m prep[pred_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(x)))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Get the rank of each retrieved QID\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m ranks \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x[pred_col])) \u001b[38;5;28;01mif\u001b[39;00m (x[pred_col][i] \u001b[38;5;129;01min\u001b[39;00m x[true_cols])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate the DCG, the Ideal DCG and finally return the NDCG\u001b[39;00m\n\u001b[1;32m     18\u001b[0m dcg \u001b[38;5;241m=\u001b[39m ranks\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog2(y\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m x]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1095\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     out\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1095\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1096\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[1;32m   1097\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def calculate_mrr_score(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    # Return the MRR\n",
    "    return ranks.apply(lambda x: 1/x[0] if len(x)>0 else 0).mean()\n",
    "\n",
    "def calculate_ndcg_score(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    # Calculate the DCG, the Ideal DCG and finally return the NDCG\n",
    "    dcg = ranks.apply(lambda x: sum([1/np.log2(y+1) for y in x]) if len(x)>0 else 0)\n",
    "    idcg = df.apply(lambda x: sum([1/np.log2(y+1) for y in range(1, min(len(x[true_cols]), len(x[pred_col])) + 1)]), axis=1)\n",
    "    return (dcg/idcg).mean()\n",
    "\n",
    "\n",
    "directory = '../data/Evaluation Data/Language Results Balanced/LC_QuAD'\n",
    "for file in os.listdir(directory):\n",
    "    print(file)\n",
    "    filename = f\"{directory}/{file}\"\n",
    "    prep = pickle.load(open(filename, \"rb\"))\n",
    "    if (pd.isna(prep['Retrieval QIDs']) | prep['Retrieval QIDs'].apply(lambda x: len(x) == 0)).sum() != 0:\n",
    "        print(\"Evaluation not complete\")\n",
    "        continue\n",
    "\n",
    "    # For Mintaka, LC_QuAD, and RuBQ\n",
    "    prep = prep[prep.apply(lambda x: all(x['Question in Wikipedia'] + x['Answer in Wikipedia']), axis=1)]\n",
    "    prep['Correct QIDs'] = prep.apply(lambda x: x['Question QIDs'] + x['Answer QIDs'], axis=1)\n",
    "\n",
    "    # For REDFM\n",
    "    # prep = prep[prep['Correct in Wikipedia']]\n",
    "    # prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "    print(\"MRR:\")\n",
    "    print(calculate_mrr_score(prep, 'Retrieval QIDs', 'Correct QIDs'))\n",
    "    print(\"NDCG:\")\n",
    "    print(calculate_ndcg_score(prep, 'Retrieval QIDs', 'Correct QIDs'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidataDB import WikidataEntity\n",
    "from wikidataEmbed import WikidataTextifier, JinaAIReranker\n",
    "\n",
    "collection = \"wikidata_test_v1\"\n",
    "evaluation_dataset = \"Mintaka\"\n",
    "filename = f\"retrieval_results_{evaluation_dataset}-{collection}-de_DB-EN_Query-DE\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/{filename}.pkl\", \"rb\"))\n",
    "\n",
    "textifier = WikidataTextifier(with_claim_aliases=False, with_property_aliases=False, language='en')\n",
    "reranker = JinaAIReranker()\n",
    "\n",
    "def rerank_qids(query, qids, reranker, textifier):\n",
    "    entities = [WikidataEntity.get_entity(qid) for qid in qids]\n",
    "    texts = [textifier.entity_to_text(entity) for entity in entities]\n",
    "    scores = reranker.rank(query, texts)\n",
    "\n",
    "    score_zip = zip(scores, prep.iloc[0]['Retrieval QIDs'])\n",
    "    score_zip = sorted(score_zip, key=lambda x: -x[0])\n",
    "    return [x[1] for x in score_zip]\n",
    "\n",
    "scores = rerank_qids(prep.iloc[0]['Question'], prep.iloc[0]['Retrieval QIDs'], reranker, textifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"retrieval_results_{evaluation_dataset}-{collection}-en_DB-EN_Query-EN\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/{filename}.pkl\", \"rb\"))\n",
    "prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def calculate_accuracy_score(df):\n",
    "    highest_score_idx = df['Retrieval Score'].apply(np.argmax)\n",
    "    top_qid = df.apply(lambda x: x['Retrieval QIDs'][highest_score_idx[x.name]], axis=1)\n",
    "    return (top_qid == df['Correct QID']).mean()\n",
    "\n",
    "def calculate_log_odds_ratio_score(df):\n",
    "    def log_odds_ratio(row):\n",
    "        correct_qid = row['Correct QID']\n",
    "        wrong_qid = row['Wrong QID']\n",
    "\n",
    "        # Find the maximum scores for the correct and wrong QIDs\n",
    "        correct_scores = [score for qid, score in zip(row['Retrieval QIDs'], row['Retrieval Score']) if qid == correct_qid]\n",
    "        wrong_scores = [score for qid, score in zip(row['Retrieval QIDs'], row['Retrieval Score']) if qid == wrong_qid]\n",
    "\n",
    "        max_correct_score = max(correct_scores, default=0)\n",
    "        max_wrong_score = max(wrong_scores, default=0)\n",
    "\n",
    "        correct_log_odds = np.log(max_correct_score / (1 - max_correct_score))\n",
    "        wrong_log_odds = np.log(max_wrong_score / (1 - max_wrong_score))\n",
    "        return correct_log_odds - wrong_log_odds\n",
    "\n",
    "    # Apply the log odds ratio calculation to each row\n",
    "    return df.apply(log_odds_ratio, axis=1).mean()\n",
    "\n",
    "collection = \"wikidata_test_v2\"\n",
    "evaluation_dataset = \"Wikidata-Disamb\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "\n",
    "calculate_accuracy_score(prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_accuracy_over_K(df, pred_col, true_cols):\n",
    "    # Remove duplicate QIDs while keeping the order\n",
    "    prep[pred_col] = prep[pred_col].apply(lambda x: list(dict.fromkeys(x)))\n",
    "    # Get the rank of each retrieved QID\n",
    "    ranks = df.apply(lambda x: [i+1 for i in range(len(x[pred_col])) if (x[pred_col][i] in x[true_cols])], axis=1)\n",
    "    ranks = ranks.apply(lambda x: min(x) if len(x) > 0 else None)\n",
    "\n",
    "    accuracy = [(ranks <= i).mean() for i in range(int(ranks.max()))]\n",
    "    return accuracy\n",
    "\n",
    "collection = \"wikidata_test_v1\"\n",
    "evaluation_dataset = \"REDFM\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "prep = prep[prep['Correct in Wikipedia']]\n",
    "prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "accuracy_v1 = calculate_accuracy_over_K(prep, 'Retrieval QIDs', 'Correct QIDs')\n",
    "\n",
    "collection = \"wikidata_test_v2\"\n",
    "evaluation_dataset = \"REDFM\"\n",
    "prep = pickle.load(open(f\"../data/Evaluation Data/retrieval_results_{evaluation_dataset}-{collection}-en.pkl\", \"rb\"))\n",
    "assert pd.isna(prep['Retrieval QIDs']).sum() == 0, \"Evaluation not complete\"\n",
    "prep = prep[prep['Correct in Wikipedia']]\n",
    "prep['Correct QIDs'] = prep['Correct QID'].apply(lambda x: [x])\n",
    "\n",
    "accuracy_v2 = calculate_accuracy_over_K(prep, 'Retrieval QIDs', 'Correct QIDs')\n",
    "\n",
    "# Create a simple bar chart\n",
    "plt.plot(list(range(len(accuracy_v1))), np.array(accuracy_v1)*100, label='Jina')\n",
    "plt.plot(list(range(len(accuracy_v2))), np.array(accuracy_v2)*100, label='Nvidia')\n",
    "plt.title('Accuracy of 1 correct item in REDFM')\n",
    "plt.xlabel('# Entities Retrieved')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.sql import func\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Modified query with random ordering\n",
    "sample_count = sample_ids['from Evaluation'].sum()*2 - (~sample_ids['from Evaluation']).sum()\n",
    "with tqdm(total=sample_count) as progressbar:\n",
    "    with Session() as session:\n",
    "        entities = (\n",
    "            session.query(WikidataID)\n",
    "            .filter(WikidataID.in_wikipedia == True)\n",
    "            .order_by(func.random())  # Adds random ordering\n",
    "            .yield_per(1000)\n",
    "        )\n",
    "\n",
    "        # Example of iterating through the entities\n",
    "        for entity in tqdm(entities):\n",
    "            if entity.id not in sample_ids['QID'].values:\n",
    "                sample_ids = pd.concat([sample_ids, pd.DataFrame([{\n",
    "                        'QID': entity.id,\n",
    "                        'from Evaluation': False,\n",
    "                        'In Wikipedia': True,\n",
    "                        'Sample 2': True\n",
    "                    }])], ignore_index=True)\n",
    "                progressbar.update(1)\n",
    "            if progressbar.n >= sample_count:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# prep = pickle.load(open(\"/home/philippe.saade/GitHub/WikidataTextEmbedding/data/Evaluation Data/KGConv/processed_dataframe.pkl\", \"rb\"))\n",
    "\n",
    "sample_ids = pickle.load(open(\"../data/Evaluation Data/Sample IDs (EN).pkl\", \"rb\"))\n",
    "sample_ids = sample_ids[sample_ids['In Wikipedia']]\n",
    "\n",
    "sample_qids_set = set(sample_ids['QID'].values)\n",
    "\n",
    "# Use vectorized operations for 'not_in_sample'\n",
    "# prep['Question in Wikipedia'] = prep['Question QID'].isin(sample_qids_set)\n",
    "# prep['Answer in Wikipedia'] = prep['Answer QID'].isin(sample_qids_set)\n",
    "# prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids[sample_ids['Sample 2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(prep.iterrows()):\n",
    "    for i in range(len(row['Answer QIDs'])):\n",
    "        if row['Answer in Wikipedia'][i] and row['Answer QIDs'][i] not in sample_qids_set:\n",
    "            sample_ids = pd.concat([sample_ids, pd.DataFrame([{\n",
    "                'QID': row['Answer QIDs'][i],\n",
    "                'from Evaluation': True,\n",
    "                'In Wikipedia': True,\n",
    "                'from Evaluation 2': True\n",
    "            }])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spans(sentence, spans, replace_with='Entity'):\n",
    "    # Sort spans in ascending order to remove from left to right\n",
    "    spans = sorted(spans, key=lambda x: x[0])\n",
    "    offset = 0  # To track the shift in index after replacing each span\n",
    "\n",
    "    for start, end in spans:\n",
    "        sentence = sentence[:start - offset] + replace_with + sentence[end - offset:]\n",
    "        offset += (end - start) - len(replace_with)  # Update offset to account for the replaced span length\n",
    "\n",
    "    return sentence\n",
    "\n",
    "data['Sentence no entity'] = data.apply(lambda x: remove_spans(x['Sentence'], x['Entity Span']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
